{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2161046,"sourceType":"datasetVersion","datasetId":1297165},{"sourceId":95769,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":80327,"modelId":104748}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\nroot_dir = \"/kaggle/input/kvasir-v2-a-gastrointestinal-tract-dataset\"\ndest_directory = \"/kaggle/working/dataset\"\nif not os.path.exists(dest_directory):\n    os.mkdir(dest_directory)\n\nfor directory in os.listdir(root_dir):\n    dir_path = os.path.join(root_dir, directory)\n    destination = os.path.join(dest_directory, directory)\n    if not os.path.exists(destination):\n        os.mkdir(destination)\n    for directory2 in os.listdir(dir_path):\n        dir_path2 = os.path.join(dir_path, directory2)\n        for image in os.listdir(dir_path2):\n            image_path = os.path.join(dir_path2, image)\n            dest_path = os.path.join(destination, image)\n            shutil.copy(image_path, dest_path)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-16T12:01:42.265592Z","iopub.execute_input":"2024-08-16T12:01:42.266556Z","iopub.status.idle":"2024-08-16T12:02:50.833631Z","shell.execute_reply.started":"2024-08-16T12:01:42.266520Z","shell.execute_reply":"2024-08-16T12:02:50.832588Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\n\ndef list_physical_devices(device_type=None):\n    devices = []\n    if device_type is None or device_type == 'cpu':\n        devices.append('cpu')\n    if device_type is None or device_type == 'cuda':\n        if torch.cuda.is_available():\n            for i in range(torch.cuda.device_count()):\n                devices.append(f'cuda:{i}')\n    return devices\n\nprint(list_physical_devices())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:02:50.835306Z","iopub.execute_input":"2024-08-16T12:02:50.835624Z","iopub.status.idle":"2024-08-16T12:02:58.036648Z","shell.execute_reply.started":"2024-08-16T12:02:50.835599Z","shell.execute_reply":"2024-08-16T12:02:58.035440Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['cpu']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nfrom torchvision.models import resnet18\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, accuracy_score\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:58:08.805060Z","iopub.execute_input":"2024-08-16T10:58:08.806022Z","iopub.status.idle":"2024-08-16T10:58:08.812731Z","shell.execute_reply.started":"2024-08-16T10:58:08.805983Z","shell.execute_reply":"2024-08-16T10:58:08.811556Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split, Subset\nfrom torchvision import datasets, transforms\n\n# Parameters\ndataset_path = \"/kaggle/working/dataset\"\nimage_size = (224, 224)\nbatch_size = 64\nvalidation_split = 0.2\nrandom_seed = 23\nnum_workers = 4  # Number of subprocesses for data loading\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load the dataset\nfull_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n\n# Get class names\nclass_names = full_dataset.classes\nprint(\"Class names:\", class_names)\n\n# Split the dataset into training and validation sets\ndataset_size = len(full_dataset)\nval_size = int(validation_split * dataset_size)\ntrain_size = dataset_size - val_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(random_seed))\n\n# Further split the validation set into validation and test sets\nval_size = len(val_dataset)\ntest_size = val_size // 2\nval_size = val_size - test_size\nval_dataset, test_dataset = random_split(val_dataset, [val_size, test_size], generator=torch.Generator().manual_seed(random_seed))\n\n# Create DataLoader for training, validation, and test sets\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:58:09.299995Z","iopub.execute_input":"2024-08-16T10:58:09.300420Z","iopub.status.idle":"2024-08-16T10:58:09.347979Z","shell.execute_reply.started":"2024-08-16T10:58:09.300370Z","shell.execute_reply":"2024-08-16T10:58:09.346837Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Class names: ['dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', 'normal-cecum', 'normal-pylorus', 'normal-z-line', 'polyps', 'ulcerative-colitis']\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"class_names = full_dataset.classes\nprint(\"Class names:\", class_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:58:10.624610Z","iopub.execute_input":"2024-08-16T10:58:10.625657Z","iopub.status.idle":"2024-08-16T10:58:10.630925Z","shell.execute_reply.started":"2024-08-16T10:58:10.625613Z","shell.execute_reply":"2024-08-16T10:58:10.629639Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Class names: ['dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', 'normal-cecum', 'normal-pylorus', 'normal-z-line', 'polyps', 'ulcerative-colitis']\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\n\nclass CustomResNet50(nn.Module):\n    def __init__(self, num_classes=8):\n        super(CustomResNet50, self).__init__()\n        # Load a pre-trained ResNet50 model without the top layer\n        self.base_model = models.resnet50(pretrained=True)\n        \n        # Remove the final fully connected layer\n        self.base_model = nn.Sequential(*list(self.base_model.children())[:-2])\n        \n        # Get the number of features in the final layer\n        in_features = self.base_model[-1][-1].conv1.in_channels\n        \n        # Add a global average pooling layer\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        \n        # Add a new fully connected layer for classification\n        self.fc = nn.Linear(in_features, num_classes)\n    \n    def forward(self, x):\n        x = self.base_model(x)\n        x = self.pool(x)\n        x = torch.flatten(x, 1)  # Flatten the output\n        x = self.fc(x)  # Final classification layer\n        return x\n\n# Instantiate the model\nmodel = CustomResNet50(num_classes=8)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define the optimizer\noptimizer = optim.AdamW(\n    model.parameters(),\n    lr=0.001,\n    weight_decay=0.004,\n    betas=(0.9, 0.999),\n    eps=1e-8\n)\n\n# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Model summary\nprint(model)\n\n# Example usage\n# inputs = torch.randn(1, 3, 224, 224)  # Example input tensor\n# outputs = model(inputs)\n# print(outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:55:04.746469Z","iopub.execute_input":"2024-08-16T11:55:04.747477Z","iopub.status.idle":"2024-08-16T11:55:25.693104Z","shell.execute_reply.started":"2024-08-16T11:55:04.747420Z","shell.execute_reply":"2024-08-16T11:55:25.691499Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1448\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:942\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:824\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    823\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 824\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    825\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n","File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n","\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCustomResNet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n","Cell \u001b[0;32mIn[38], line 10\u001b[0m, in \u001b[0;36mCustomResNet50.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28msuper\u001b[39m(CustomResNet50, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load a pre-trained ResNet50 model without the top layer\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Remove the final fully connected layer\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mchildren())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[1;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/resnet.py:763\u001b[0m, in \u001b[0;36mresnet50\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"ResNet-50 from `Deep Residual Learning for Image Recognition <https://arxiv.org/abs/1512.03385>`__.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m.. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;124;03m    :members:\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    761\u001b[0m weights \u001b[38;5;241m=\u001b[39m ResNet50_Weights\u001b[38;5;241m.\u001b[39mverify(weights)\n\u001b[0;32m--> 763\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBottleneck\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/resnet.py:301\u001b[0m, in \u001b[0;36m_resnet\u001b[0;34m(block, layers, weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet(block, layers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/_api.py:90\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/hub.py:766\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    764\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    765\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/hub.py:620\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    618\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    619\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.hub\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m--> 620\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m meta \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(meta, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetheaders\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n","\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -3] Temporary failure in name resolution>"],"ename":"URLError","evalue":"<urlopen error [Errno -3] Temporary failure in name resolution>","output_type":"error"}],"execution_count":38},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport os\nimport numpy as np\n\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, min_lr=1e-5)\n\nclass EarlyStopping:\n    def __init__(self, patience=20, verbose=False, delta=0):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.verbose:\n                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), 'checkpoint.pt')\n        self.val_loss_min = val_loss\n\nearly_stopping = EarlyStopping(patience=20, verbose=True)\n\nbest_val_accuracy = 0.0\nbest_model_path = \"training_weights/best/model_best_val_accuracy.ckpt\"\nos.makedirs(os.path.dirname(best_model_path), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:02:24.621202Z","iopub.execute_input":"2024-08-16T11:02:24.621699Z","iopub.status.idle":"2024-08-16T11:02:24.671688Z","shell.execute_reply.started":"2024-08-16T11:02:24.621663Z","shell.execute_reply":"2024-08-16T11:02:24.670243Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\u001b[43moptimizer\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEarlyStopping\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n","\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"],"ename":"NameError","evalue":"name 'optimizer' is not defined","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"# Training loop\nnum_epochs = 30\nfor epoch in range(num_epochs):\n    model.train()\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_loss /= len(val_loader)\n    val_accuracy = correct / total\n    \n    scheduler.step(val_loss)\n    early_stopping(val_loss, model)\n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break\n    \n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"Saved best model with accuracy: {best_val_accuracy:.4f}\")\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n\n# Load the best model for evaluation\nmodel.load_state_dict(torch.load(best_model_path))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:40:18.136214Z","iopub.status.idle":"2024-08-16T10:40:18.136622Z","shell.execute_reply.started":"2024-08-16T10:40:18.136411Z","shell.execute_reply":"2024-08-16T10:40:18.136427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Define the path to save the model weights\nweights_path = \"training_weights/best/model_best_val_accuracy.ckpt\"\n\n# Save the model's state_dict (weights)\ntorch.save(model.state_dict(), weights_path)\n\nprint(f\"Model weights saved to {weights_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:40:18.138134Z","iopub.status.idle":"2024-08-16T10:40:18.138507Z","shell.execute_reply.started":"2024-08-16T10:40:18.138325Z","shell.execute_reply":"2024-08-16T10:40:18.138341Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create a link to download the file\nFileLink(weights_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:40:18.140067Z","iopub.status.idle":"2024-08-16T10:40:18.140446Z","shell.execute_reply.started":"2024-08-16T10:40:18.140255Z","shell.execute_reply":"2024-08-16T10:40:18.140269Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = CustomResNet50(num_classes=8)\nmodel.load_state_dict(torch.load(\"training_weights/best/model_best_val_accuracy.ckpt\"))\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Initialize storage for labels and predictions\nall_labels = []\nall_probs = []\n\n# Get predictions\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        outputs = model(images)\n        probs = torch.softmax(outputs, dim=1)\n        \n        all_labels.extend(labels.cpu().numpy())\n        all_probs.extend(probs.cpu().numpy())\n\nall_labels = np.array(all_labels)\nall_probs = np.array(all_probs)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:40:18.143152Z","iopub.status.idle":"2024-08-16T10:40:18.143565Z","shell.execute_reply.started":"2024-08-16T10:40:18.143366Z","shell.execute_reply":"2024-08-16T10:40:18.143389Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, precision_recall_curve\n# Initialize dictionaries to store thresholds and metrics\nthresholds = {}\noptimal_thresholds = {}\n\nclasses = class_names\n# Iterate over each class\nfor i in range(len(classes)):\n    fpr, tpr, roc_thresholds = roc_curve(all_labels == i, all_probs[:, i])\n    precision, recall, pr_thresholds = precision_recall_curve(all_labels == i, all_probs[:, i])\n    \n    # Example: Use Youden's J statistic to find optimal threshold from ROC\n    youdens_j = tpr - fpr\n    optimal_idx = np.argmax(youdens_j)\n    optimal_thresholds[i] = roc_thresholds[optimal_idx]\n    \n    thresholds[i] = {\n        'roc': (fpr, tpr, roc_thresholds),\n        'pr': (precision, recall, pr_thresholds),\n        'optimal': optimal_thresholds[i]\n    }\n# Print optimal thresholds for each class\nfor i, thresh in optimal_thresholds.items():\n    print(f\"Optimal threshold for class {classes[i]}: {thresh}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:40:18.147427Z","iopub.execute_input":"2024-08-16T10:40:18.147785Z","iopub.status.idle":"2024-08-16T10:40:18.187121Z","shell.execute_reply.started":"2024-08-16T10:40:18.147755Z","shell.execute_reply":"2024-08-16T10:40:18.185221Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Iterate over each class\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(classes)):\n\u001b[0;32m----> 9\u001b[0m     fpr, tpr, roc_thresholds \u001b[38;5;241m=\u001b[39m roc_curve(\u001b[43mall_labels\u001b[49m \u001b[38;5;241m==\u001b[39m i, all_probs[:, i])\n\u001b[1;32m     10\u001b[0m     precision, recall, pr_thresholds \u001b[38;5;241m=\u001b[39m precision_recall_curve(all_labels \u001b[38;5;241m==\u001b[39m i, all_probs[:, i])\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Example: Use Youden's J statistic to find optimal threshold from ROC\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'all_labels' is not defined"],"ename":"NameError","evalue":"name 'all_labels' is not defined","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"import torch\n\n# Define the model architecture again (if not already defined)\nclass CustomResNet50(nn.Module):\n    def __init__(self, num_classes=8):\n        super(CustomResNet50, self).__init__()\n        # Load a pre-trained ResNet50 model without the top layer\n        self.base_model = models.resnet50(pretrained=True)\n        \n        # Remove the final fully connected layer\n        self.base_model = nn.Sequential(*list(self.base_model.children())[:-2])\n        \n        # Get the number of features in the final layer\n        in_features = self.base_model[-1][-1].conv1.in_channels\n        \n        # Add a global average pooling layer\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        \n        # Add a new fully connected layer for classification\n        self.fc = nn.Linear(in_features, num_classes)\n    \n    def forward(self, x):\n        x = self.base_model(x)\n        x = self.pool(x)\n        x = torch.flatten(x, 1)  # Flatten the output\n        x = self.fc(x)  # Final classification layer\n        return x\n\n# Instantiate the model\nmodel = CustomResNet50(num_classes=8)\n\n# Move the model to the appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Load the checkpoint\ncheckpoint_path = '/kaggle/input/kvasir/pytorch/default/1/model_best_val_accuracy.ckpt'\ncheckpoint = torch.load(checkpoint_path, map_location=device)\n\n# Load the state_dict into the model\nmodel.load_state_dict(checkpoint)\n\n# Set the model to evaluation mode\nmodel.eval()\n\nprint(\"Model weights loaded successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:40:18.187982Z","iopub.status.idle":"2024-08-16T10:40:18.188396Z","shell.execute_reply.started":"2024-08-16T10:40:18.188185Z","shell.execute_reply":"2024-08-16T10:40:18.188200Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\nfrom PIL import Image\n\n# Define the image transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize the image to 224x224\n    transforms.ToTensor(),  # Convert the image to a tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n])\n\n# Load and preprocess the image\nimage_path = '/kaggle/input/kvasir-v2-a-gastrointestinal-tract-dataset/dyed-lifted-polyps/dyed-lifted-polyps/0053d7cd-549c-48cd-b370-b4ad64a8098a.jpg'  # Replace with your image path\nimage = Image.open(image_path)\nimage = transform(image)\nimage = image.unsqueeze(0)  # Add batch dimension\n\n# Move the image to the same device as the model\nimage = image.to(device)\n\n# Perform the classification\nwith torch.no_grad():  # Disable gradient calculation for inference\n    output = model(image)\n    _, predicted = torch.max(output, 1)\n    print('Predicted class:', predicted.item())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T10:40:18.190081Z","iopub.status.idle":"2024-08-16T10:40:18.190653Z","shell.execute_reply.started":"2024-08-16T10:40:18.190326Z","shell.execute_reply":"2024-08-16T10:40:18.190347Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}